# End-to-end latency versus normalized vehicle density. The proposed Hydra-RAN maintains superior performance across all traffic conditions, with particularly pronounced gains in high-density scenarios.

# -*- coding: utf-8 -*-
"""
Dynamic Performance Evaluation Simulation Framework
IEEE Transactions on Communications
Hydra-RAN Enhanced Autonomous Vehicles

Author: Rafid I. Abd et al.
Modified: Fully dynamic and responsive simulation framework
"""

import numpy as np
import matplotlib.pyplot as plt
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Callable, Any
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# ===============================
# IEEE TCOM Global Style
# ===============================
plt.rcParams.update({
    "font.family": "Times New Roman",
    "axes.linewidth": 1.4,
    "axes.edgecolor": "0.2",
    "figure.figsize": (14, 10),
    "font.size": 12
})

# ===============================
# Enhanced Data Structures
# ===============================

class ApproachType(Enum):
    """Types of approaches for categorization."""
    BASELINE = "baseline"
    PROPOSED = "proposed"
    HYBRID = "hybrid"

@dataclass
class DynamicParameters:
    """Centralized dynamic simulation parameters."""
    # Latency parameters
    latency_min: float = 10.0
    latency_max: float = 120.0
    latency_points: int = 20
    
    # Network parameters
    bandwidth: float = 100.0  # MHz
    noise_power: float = -174.0  # dBm/Hz
    tx_power: float = 23.0  # dBm
    path_loss_exponent: float = 3.5
    shadowing_std: float = 8.0
    network_congestion: float = 0.3  # 0-1 scale
    
    # Dataset parameters
    dataset_size: int = 1000
    feature_dim: int = 512
    num_classes: int = 10
    
    # KD model parameters with dynamic ranges
    kd_alpha_range: Tuple[float, float] = (0.001, 0.05)
    kd_beta_range: Tuple[float, float] = (0.001, 0.02)
    kd_max_gain_range: Tuple[float, float] = (20.0, 100.0)
    
    # System parameters
    vehicle_density: float = 50.0  # vehicles/km²
    rsu_density: float = 5.0  # RSUs/km
    mobility_speed: float = 60.0  # km/h
    channel_coherence_time: float = 10.0  # ms
    packet_loss_rate: float = 0.05  # 0-1
    
    # Computation parameters
    gpu_capacity: float = 10.0  # TFLOPS
    memory_budget: float = 8.0  # GB
    energy_budget: float = 100.0  # Watt-hours
    
    # Performance weights
    weight_latency: float = 0.3
    weight_reliability: float = 0.3
    weight_accuracy: float = 0.4
    weight_energy: float = 0.1
    
    # Random seed
    seed: int = 7
    
    def __post_init__(self):
        """Initialize derived parameters."""
        np.random.seed(self.seed)
        self.latency = np.linspace(
            self.latency_min, 
            self.latency_max, 
            self.latency_points
        )
        
    def update(self, **kwargs):
        """Update parameters dynamically."""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
        self.__post_init__()
        return self
    
    def compute_channel_quality(self) -> float:
        """Compute dynamic channel quality index."""
        sinr = self.tx_power - self.noise_power - 10*np.log10(self.bandwidth*1e6)
        sinr -= self.path_loss_exponent * 20 * np.log10(100)
        sinr -= np.random.randn() * self.shadowing_std
        sinr_penalty = self.packet_loss_rate * 20
        congestion_penalty = self.network_congestion * 10
        return max(0.1, sinr - sinr_penalty - congestion_penalty) / 100
    
    def compute_system_load(self) -> float:
        """Compute normalized system load dynamically."""
        comm_load = (self.vehicle_density * self.mobility_speed) / \
                    (self.rsu_density * self.bandwidth)
        comp_load = self.feature_dim * self.num_classes / (self.gpu_capacity * 1000)
        return min(1.0, 0.6 * comm_load + 0.4 * comp_load)
    
    def compute_energy_efficiency(self) -> float:
        """Compute energy efficiency factor."""
        energy_per_operation = 0.1 * (self.feature_dim / 512) * (self.num_classes / 10)
        available_energy = self.energy_budget / 100
        return min(1.0, available_energy / (energy_per_operation + 0.1))

@dataclass
class DynamicDataset:
    """Represents dynamic input dataset characteristics."""
    name: str
    size: int
    feature_dim: int
    num_classes: int
    complexity: float  # 0-1 scale
    noise_level: float  # 0-1 scale
    spatial_variation: float  # 0-1 scale
    temporal_variation: float  # 0-1 scale
    label_noise: float  # 0-1 scale
    data_drift_rate: float  # 0-1 scale
    imbalance_ratio: float = 0.2
    missing_data_rate: float = 0.05
    
    def __post_init__(self):
        """Initialize dynamic properties."""
        self.current_complexity = self.complexity
        self.current_noise = self.noise_level
        self.current_variation = self.spatial_variation
        self.drift_counter = 0
        
    def apply_drift(self, step: int = 1):
        """Apply data drift over time."""
        self.drift_counter += step
        drift_factor = 1 + self.data_drift_rate * np.sin(self.drift_counter / 10)
        noise_factor = 1 + 0.2 * np.sin(self.drift_counter / 5)
        
        self.current_complexity = min(1.0, self.complexity * drift_factor)
        self.current_noise = min(1.0, self.noise_level * noise_factor)
        self.current_variation = min(1.0, self.spatial_variation * drift_factor)
        
    def get_impact_factors(self, params: DynamicParameters) -> Dict[str, float]:
        """Calculate dynamic impact factors on model performance."""
        channel_quality = params.compute_channel_quality()
        system_load = params.compute_system_load()
        energy_efficiency = params.compute_energy_efficiency()
        
        return {
            'data_quality': max(0.1, 1.0 - self.current_noise - self.label_noise - self.missing_data_rate),
            'model_complexity': self.current_complexity * (1 + 0.5 * np.log2(self.num_classes)),
            'variability': self.current_variation * (1 + self.temporal_variation),
            'channel_quality': channel_quality,
            'system_load': system_load,
            'energy_efficiency': energy_efficiency,
            'data_freshness': 1.0 - min(1.0, self.drift_counter / 100),
            'imbalance_effect': 1.0 - 0.3 * self.imbalance_ratio
        }
    
    def generate_performance_noise(self, base_value: float, params: DynamicParameters) -> float:
        """Add dataset-specific performance noise."""
        variability = self.get_impact_factors(params)['variability']
        noise_magnitude = variability * 0.15 * base_value
        return base_value * (1 + np.random.randn() * 0.1) + np.random.randn() * noise_magnitude

# ===============================
# Dynamic Core Functions
# ===============================

def dynamic_kd_gain(lat: np.ndarray, alpha: float, beta: float, 
                   max_gain: float, factors: Dict[str, float],
                   approach_type: ApproachType) -> np.ndarray:
    """
    Dynamic KD gain model with multiple influencing factors.
    """
    # Base saturating curve
    base_gain = max_gain * (1 - np.exp(-alpha * lat)) * np.exp(-beta * lat)
    
    # Apply approach-specific scaling
    if approach_type == ApproachType.PROPOSED:
        # Hydra-RAN benefits more from good conditions
        channel_effect = 0.6 + 0.4 * factors['channel_quality']
        data_quality_boost = 0.6 + 0.4 * factors['data_quality']
        complexity_benefit = 1 + 0.3 * factors['model_complexity']
    elif approach_type == ApproachType.HYBRID:
        # Hybrid approaches have moderate benefits
        channel_effect = 0.5 + 0.5 * factors['channel_quality']
        data_quality_boost = 0.7 + 0.3 * factors['data_quality']
        complexity_benefit = 1 + 0.2 * factors['model_complexity']
    else:
        # Baseline approaches have standard scaling
        channel_effect = 0.4 + 0.6 * factors['channel_quality']
        data_quality_boost = 0.8 + 0.2 * factors['data_quality']
        complexity_benefit = 1 + 0.1 * factors['model_complexity']
    
    # Apply all effects
    base_gain *= channel_effect
    base_gain *= data_quality_boost
    base_gain *= complexity_benefit
    
    # Apply system load penalty
    load_penalty = 1.0 - 0.4 * factors['system_load']
    base_gain *= load_penalty
    
    # Apply energy efficiency effect
    energy_effect = 0.7 + 0.3 * factors['energy_efficiency']
    base_gain *= energy_effect
    
    # Apply data imbalance effect
    base_gain *= factors['imbalance_effect']
    
    # Add variability-based noise
    variability_noise = factors['variability'] * 0.1 * base_gain
    base_gain += np.random.randn(len(lat)) * variability_noise
    
    return np.clip(base_gain, 0, max_gain * 1.3)

def compute_reliability(lat: np.ndarray, factors: Dict[str, float], 
                       packet_loss_rate: float) -> np.ndarray:
    """Compute reliability as function of latency and conditions."""
    base_reliability = np.exp(-lat / 100)
    channel_effect = factors['channel_quality']
    load_effect = 1.0 - 0.5 * factors['system_load']
    packet_loss_effect = 1.0 - packet_loss_rate
    
    reliability = base_reliability * channel_effect * load_effect * packet_loss_effect
    
    # Add small noise
    reliability *= (1 + np.random.randn(len(lat)) * 0.05)
    
    return np.clip(reliability, 0, 1)

def compute_accuracy(gain: np.ndarray, factors: Dict[str, float]) -> np.ndarray:
    """Compute accuracy from KD gain and conditions."""
    base_accuracy = 0.7 + 0.3 * (gain / 100)
    data_quality_effect = 0.5 + 0.5 * factors['data_quality']
    complexity_effect = 1.0 - 0.2 * factors['model_complexity']
    
    accuracy = base_accuracy * data_quality_effect * complexity_effect
    
    # Apply freshness effect
    freshness_effect = 0.8 + 0.2 * factors['data_freshness']
    accuracy *= freshness_effect
    
    return np.clip(accuracy, 0.5, 0.99)

def compute_energy_consumption(lat: np.ndarray, gain: np.ndarray, 
                             factors: Dict[str, float]) -> np.ndarray:
    """Compute energy consumption."""
    base_energy = 0.1 * lat + 0.01 * gain  # Simplified model
    energy_efficiency = factors['energy_efficiency']
    load_penalty = 1 + 0.5 * factors['system_load']
    
    return base_energy * load_penalty / (energy_efficiency + 0.1)

def compute_composite_score(gain: np.ndarray, lat: np.ndarray, 
                           reliability: np.ndarray, accuracy: np.ndarray,
                           energy: np.ndarray, weights: Tuple) -> np.ndarray:
    """Compute composite performance score."""
    # Normalize metrics
    norm_gain = gain / 100
    norm_lat = 1.0 - (lat - lat.min()) / (lat.max() - lat.min())
    norm_rel = reliability
    norm_acc = accuracy
    norm_energy = 1.0 - (energy - energy.min()) / (energy.max() - energy.min() + 1e-10)
    
    # Weighted sum
    return (weights[0] * norm_gain + 
            weights[1] * norm_lat + 
            weights[2] * norm_rel + 
            weights[3] * norm_acc + 
            weights[4] * norm_energy)

# ===============================
# Dynamic Approach System
# ===============================

class DynamicApproach:
    """Dynamic approach configuration with adaptive parameters."""
    
    def __init__(self, name: str, approach_type: ApproachType,
                 base_alpha: float, base_beta: float, base_max_gain: float,
                 adaptation_rate: float = 0.1,
                 metadata: Optional[Dict] = None):
        self.name = name
        self.approach_type = approach_type
        self.base_alpha = base_alpha
        self.base_beta = base_beta
        self.base_max_gain = base_max_gain
        self.adaptation_rate = adaptation_rate
        self.metadata = metadata or {}
        self.performance_history = []
        self.parameter_history = []
        
        # Set dynamic plot style
        if self.approach_type == ApproachType.PROPOSED:
            self.plot_style = {'color': 'k', 'linewidth': 5, 'linestyle': '-', 'alpha': 0.9}
        elif self.approach_type == ApproachType.HYBRID:
            self.plot_style = {'color': 'purple', 'linewidth': 3, 'linestyle': '--', 'marker': 'o'}
        else:
            markers = ['s', '^', 'd', 'v', 'p', 'h', '8']
            colors = ['b', 'g', 'r', 'c', 'm', 'y', 'orange']
            idx = hash(self.name) % len(markers)
            self.plot_style = {
                'marker': markers[idx],
                'linestyle': '-',
                'markersize': 8,
                'linewidth': 2,
                'color': colors[idx],
                'alpha': 0.7
            }
    
    def adapt_parameters(self, factors: Dict[str, float], 
                        params: DynamicParameters, 
                        previous_params: Optional[Dict] = None) -> Dict[str, float]:
        """Dynamically adapt parameters based on current conditions."""
        
        # Base adaptations
        alpha_adapt = factors['data_quality'] * (1 - 0.3 * factors['system_load'])
        beta_adapt = (1 + factors['variability']) * (1 + 0.2 * factors['system_load'])
        gain_adapt = (1 + 0.4 * factors['model_complexity']) * factors['channel_quality']
        
        # Approach-specific adaptations
        if 'hierarchical' in self.metadata.get('features', []):
            # Hydra-RAN specific adaptations
            alpha_adapt *= 1.2  # Faster learning
            beta_adapt *= 0.7   # Less sensitive to latency
            gain_adapt *= 1.3   # Higher gain potential
            # Adapt to energy efficiency
            gain_adapt *= (0.8 + 0.4 * factors['energy_efficiency'])
            
        elif 'federated' in self.metadata.get('model_type', ''):
            # Federated learning adaptations
            gain_adapt *= factors['data_freshness']
            alpha_adapt *= 0.9  # Slower convergence
            beta_adapt *= 1.1   # More sensitive to latency
            
        elif 'semantic' in self.metadata.get('model_type', ''):
            # Semantic communication adaptations
            gain_adapt *= (0.7 + 0.3 * factors['channel_quality'])
            alpha_adapt *= 1.1
            beta_adapt *= 0.9
            
        # Apply adaptation with momentum if previous parameters exist
        if previous_params:
            momentum = 0.3
            alpha_adapt = momentum * previous_params['alpha'] + (1 - momentum) * alpha_adapt
            beta_adapt = momentum * previous_params['beta'] + (1 - momentum) * beta_adapt
            gain_adapt = momentum * previous_params['max_gain'] + (1 - momentum) * gain_adapt
        
        # Compute adapted parameters
        adapted_alpha = self.base_alpha * alpha_adapt
        adapted_beta = self.base_beta * beta_adapt
        adapted_max_gain = self.base_max_gain * gain_adapt
        
        # Clip to valid ranges
        adapted_alpha = np.clip(adapted_alpha, 
                               params.kd_alpha_range[0], 
                               params.kd_alpha_range[1])
        adapted_beta = np.clip(adapted_beta,
                              params.kd_beta_range[0],
                              params.kd_beta_range[1])
        adapted_max_gain = np.clip(adapted_max_gain,
                                  params.kd_max_gain_range[0],
                                  params.kd_max_gain_range[1])
        
        # Add small random variation for realism (10% chance)
        if np.random.rand() < 0.1:
            variation = np.random.uniform(0.95, 1.05)
            adapted_max_gain *= variation
            
        return {
            'alpha': adapted_alpha,
            'beta': adapted_beta,
            'max_gain': adapted_max_gain
        }
    
    def compute_performance(self, lat: np.ndarray, params: DynamicParameters,
                          factors: Dict[str, float]) -> Dict[str, np.ndarray]:
        """Compute complete performance metrics."""
        # Get adapted parameters
        prev_params = self.parameter_history[-1] if self.parameter_history else None
        adapted_params = self.adapt_parameters(factors, params, prev_params)
        self.parameter_history.append(adapted_params)
        
        # Compute KD gain
        kd_gain = dynamic_kd_gain(lat, adapted_params['alpha'], 
                                 adapted_params['beta'], adapted_params['max_gain'],
                                 factors, self.approach_type)
        
        # Add dataset-specific noise
        kd_gain = np.array([params.dataset.generate_performance_noise(v, params) 
                           for v in kd_gain])
        
        # Compute other metrics
        reliability = compute_reliability(lat, factors, params.packet_loss_rate)
        accuracy = compute_accuracy(kd_gain, factors)
        energy = compute_energy_consumption(lat, kd_gain, factors)
        
        # Composite score
        composite = compute_composite_score(
            kd_gain, lat, reliability, accuracy, energy,
            (params.weight_latency, params.weight_reliability,
             params.weight_accuracy, params.weight_energy, 0.1)
        )
        
        return {
            'kd_gain': kd_gain,
            'reliability': reliability,
            'accuracy': accuracy,
            'energy_consumption': energy,
            'composite_score': composite,
            'adapted_params': adapted_params
        }

# ===============================
# Main Dynamic Simulation Framework
# ===============================

class DynamicSimulationFramework:
    """Main dynamic simulation framework."""
    
    def __init__(self):
        self.params = DynamicParameters()
        self.dataset = None
        self.approaches: List[DynamicApproach] = []
        self.results: Dict[str, Dict] = {}
        self.history: List[Dict] = []
        self.current_step = 0
        
    def set_dataset(self, dataset: DynamicDataset):
        """Set the current dataset."""
        self.dataset = dataset
        return self
    
    def add_approach(self, approach: DynamicApproach):
        """Add an approach to simulation."""
        self.approaches.append(approach)
        return self
    
    def reset(self):
        """Reset simulation state."""
        self.results.clear()
        self.history.clear()
        self.current_step = 0
        for approach in self.approaches:
            approach.performance_history.clear()
            approach.parameter_history.clear()
        return self
    
    def simulate_step(self, step_duration: float = 1.0) -> Dict:
        """Simulate one time step."""
        if self.dataset is None:
            raise ValueError("No dataset set. Use set_dataset() first.")
        
        # Apply dataset drift
        self.dataset.apply_drift(self.current_step)
        
        # Get current environmental factors
        factors = self.dataset.get_impact_factors(self.params)
        
        # Simulate each approach
        step_results = {}
        for approach in self.approaches:
            perf = approach.compute_performance(
                self.params.latency, self.params, factors
            )
            step_results[approach.name] = perf
            approach.performance_history.append(perf)
        
        # Record system state
        system_state = {
            'step': self.current_step,
            'timestamp': self.current_step * step_duration,
            'factors': factors.copy(),
            'params': {
                'latency_range': (self.params.latency_min, self.params.latency_max),
                'bandwidth': self.params.bandwidth,
                'vehicle_density': self.params.vehicle_density,
                'dataset_complexity': self.dataset.current_complexity,
                'dataset_noise': self.dataset.current_noise,
                'channel_quality': factors['channel_quality'],
                'system_load': factors['system_load']
            },
            'results': {name: {k: v.mean() if isinstance(v, np.ndarray) else v 
                             for k, v in perf.items() if k != 'adapted_params'}
                      for name, perf in step_results.items()}
        }
        
        self.history.append(system_state)
        self.results[f'step_{self.current_step}'] = step_results
        self.current_step += 1
        
        return step_results
    
    def simulate(self, num_steps: int = 10, step_duration: float = 1.0):
        """Run multiple simulation steps."""
        self.reset()
        for _ in range(num_steps):
            self.simulate_step(step_duration)
        return self
    
    def update_parameters(self, **kwargs):
        """Update simulation parameters."""
        self.params.update(**kwargs)
        return self
    
    def modify_dataset(self, **kwargs):
        """Modify dataset characteristics."""
        if self.dataset:
            for key, value in kwargs.items():
                if hasattr(self.dataset, key):
                    setattr(self.dataset, key, value)
            # Reset drift counter when modifying dataset
            self.dataset.drift_counter = 0
        return self

# ===============================
# Visualization and Analysis
# ===============================

class SimulationVisualizer:
    """Visualization tools for dynamic simulation."""
    
    @staticmethod
    def plot_dynamic_performance(sim: DynamicSimulationFramework, 
                                step: Optional[int] = None):
        """Plot dynamic performance results."""
        if step is None:
            step = sim.current_step - 1 if sim.current_step > 0 else 0
        
        results = sim.results.get(f'step_{step}', {})
        if not results:
            print(f"No results for step {step}")
            return
        
        fig, axes = plt.subplots(3, 2, figsize=(16, 18))
        axes = axes.flatten()
        
        # Plot 1: KD Gain vs Latency
        ax = axes[0]
        for approach in sim.approaches:
            if approach.name in results:
                data = results[approach.name]
                ax.plot(sim.params.latency, data['kd_gain'], 
                       label=approach.name, **approach.plot_style)
        ax.set_xlabel('End-to-End Latency (ms)', fontsize=12)
        ax.set_ylabel('KD Gain (%)', fontsize=12)
        ax.set_title('KD Gain vs Latency (Current Step)', fontsize=14)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10, loc='best')
        
        # Plot 2: Composite Score
        ax = axes[1]
        for approach in sim.approaches:
            if approach.name in results:
                data = results[approach.name]
                ax.plot(sim.params.latency, data['composite_score'],
                       label=approach.name, **approach.plot_style)
        ax.set_xlabel('End-to-End Latency (ms)', fontsize=12)
        ax.set_ylabel('Composite Score', fontsize=12)
        ax.set_title('Composite Performance Score', fontsize=14)
        ax.grid(True, alpha=0.3)
        
        # Plot 3: Performance Over Time
        ax = axes[2]
        for approach in sim.approaches:
            if approach.performance_history:
                avg_gains = [np.mean(step['kd_gain']) 
                           for step in approach.performance_history]
                ax.plot(range(len(avg_gains)), avg_gains, 
                       label=approach.name, **approach.plot_style)
        ax.set_xlabel('Simulation Step', fontsize=12)
        ax.set_ylabel('Average KD Gain (%)', fontsize=12)
        ax.set_title('Performance Evolution Over Time', fontsize=14)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10, loc='best')
        
        # Plot 4: Parameter Adaptation
        ax = axes[3]
        for approach in sim.approaches:
            if approach.parameter_history:
                alphas = [p['alpha'] for p in approach.parameter_history]
                betas = [p['beta'] for p in approach.parameter_history]
                ax.plot(range(len(alphas)), alphas, 
                       label=f'{approach.name} (α)', 
                       linestyle='-', alpha=0.7)
                ax.plot(range(len(betas)), betas, 
                       label=f'{approach.name} (β)', 
                       linestyle='--', alpha=0.7)
        ax.set_xlabel('Simulation Step', fontsize=12)
        ax.set_ylabel('Parameter Value', fontsize=12)
        ax.set_title('Parameter Adaptation Over Time', fontsize=14)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=9, loc='best')
        
        # Plot 5: System State
        ax = axes[4]
        if sim.history:
            steps = [h['step'] for h in sim.history]
            channel_qualities = [h['factors']['channel_quality'] for h in sim.history]
            system_loads = [h['factors']['system_load'] for h in sim.history]
            data_qualities = [h['factors']['data_quality'] for h in sim.history]
            
            ax.plot(steps, channel_qualities, label='Channel Quality', 
                   linewidth=2, color='blue')
            ax.plot(steps, system_loads, label='System Load', 
                   linewidth=2, color='red')
            ax.plot(steps, data_qualities, label='Data Quality', 
                   linewidth=2, color='green')
            ax.set_xlabel('Simulation Step', fontsize=12)
            ax.set_ylabel('Normalized Value', fontsize=12)
            ax.set_title('System State Evolution', fontsize=14)
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        # Plot 6: Performance Distribution
        ax = axes[5]
        all_gains = []
        labels = []
        colors = []
        for approach in sim.approaches:
            if approach.name in results:
                avg_gain = np.mean(results[approach.name]['kd_gain'])
                all_gains.append(avg_gain)
                labels.append(approach.name)
                colors.append(approach.plot_style['color'])
        
        bars = ax.bar(range(len(all_gains)), all_gains, color=colors, alpha=0.7)
        ax.set_xticks(range(len(all_gains)))
        ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=10)
        ax.set_ylabel('Average KD Gain (%)', fontsize=12)
        ax.set_title('Performance Distribution (Current Step)', fontsize=14)
        
        plt.suptitle(f'Dynamic Performance Evaluation - Step {step}', fontsize=16)
        plt.tight_layout()
        plt.show()
    
    @staticmethod
    def plot_sensitivity_analysis(sim: DynamicSimulationFramework, 
                                 param_name: str, 
                                 values: np.ndarray):
        """Plot sensitivity analysis for a parameter."""
        original_value = getattr(sim.params, param_name)
        avg_gains = {approach.name: [] for approach in sim.approaches}
        
        for value in values:
            sim.update_parameters(**{param_name: value})
            sim.reset()
            sim.simulate(num_steps=1)
            
            for approach in sim.approaches:
                if approach.performance_history:
                    avg_gain = np.mean(approach.performance_history[-1]['kd_gain'])
                    avg_gains[approach.name].append(avg_gain)
        
        # Restore original value
        sim.update_parameters(**{param_name: original_value})
        
        # Plot
        plt.figure(figsize=(12, 8))
        for approach in sim.approaches:
            plt.plot(values, avg_gains[approach.name], 
                    label=approach.name, **approach.plot_style)
        
        plt.xlabel(f'{param_name.replace("_", " ").title()}', fontsize=14)
        plt.ylabel('Average KD Gain (%)', fontsize=14)
        plt.title(f'Sensitivity Analysis: {param_name.replace("_", " ").title()}', fontsize=16)
        plt.grid(True, alpha=0.3)
        plt.legend(fontsize=11)
        plt.tight_layout()
        plt.show()
        
        return avg_gains

# ===============================
# Dataset Factory
# ===============================

def create_dynamic_dataset_scenarios() -> Dict[str, DynamicDataset]:
    """Create dynamic dataset scenarios."""
    return {
        'urban_dynamic': DynamicDataset(
            name='Urban Driving Scenario',
            size=2000,
            feature_dim=768,
            num_classes=12,
            complexity=0.7,
            noise_level=0.4,
            spatial_variation=0.6,
            temporal_variation=0.5,
            label_noise=0.2,
            data_drift_rate=0.1,
            imbalance_ratio=0.25,
            missing_data_rate=0.08
        ),
        'highway_stable': DynamicDataset(
            name='Highway Scenario',
            size=1500,
            feature_dim=640,
            num_classes=8,
            complexity=0.5,
            noise_level=0.2,
            spatial_variation=0.3,
            temporal_variation=0.2,
            label_noise=0.1,
            data_drift_rate=0.05,
            imbalance_ratio=0.15,
            missing_data_rate=0.03
        ),
        'dense_urban': DynamicDataset(
            name='Dense Urban Scenario',
            size=3000,
            feature_dim=896,
            num_classes=18,
            complexity=0.8,
            noise_level=0.6,
            spatial_variation=0.7,
            temporal_variation=0.6,
            label_noise=0.3,
            data_drift_rate=0.15,
            imbalance_ratio=0.35,
            missing_data_rate=0.12
        ),
        'edge_case': DynamicDataset(
            name='Edge Case Scenario',
            size=800,
            feature_dim=512,
            num_classes=6,
            complexity=0.9,
            noise_level=0.8,
            spatial_variation=0.9,
            temporal_variation=0.8,
            label_noise=0.4,
            data_drift_rate=0.25,
            imbalance_ratio=0.5,
            missing_data_rate=0.2
        ),
        'mixed_traffic': DynamicDataset(
            name='Mixed Traffic Scenario',
            size=2500,
            feature_dim=832,
            num_classes=15,
            complexity=0.75,
            noise_level=0.5,
            spatial_variation=0.65,
            temporal_variation=0.55,
            label_noise=0.25,
            data_drift_rate=0.12,
            imbalance_ratio=0.3,
            missing_data_rate=0.1
        )
    }

# ===============================
# Approach Factory
# ===============================

def create_dynamic_approaches() -> List[DynamicApproach]:
    """Create dynamic approach configurations."""
    return [
        DynamicApproach(
            name='Cooperative Perception',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.015,
            base_beta=0.010,
            base_max_gain=28,
            adaptation_rate=0.1,
            metadata={'model_type': 'raw_exchange', 'features': ['basic']}
        ),
        DynamicApproach(
            name='V2X-ViTv2',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.020,
            base_beta=0.009,
            base_max_gain=40,
            adaptation_rate=0.15,
            metadata={'model_type': 'transformer', 'features': ['attention']}
        ),
        DynamicApproach(
            name='Semantic Communication',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.025,
            base_beta=0.007,
            base_max_gain=52,
            adaptation_rate=0.18,
            metadata={'model_type': 'semantic', 'features': ['semantic']}
        ),
        DynamicApproach(
            name='Task-Oriented Comm.',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.030,
            base_beta=0.006,
            base_max_gain=60,
            adaptation_rate=0.2,
            metadata={'model_type': 'task_aware', 'features': ['task']}
        ),
        DynamicApproach(
            name='Digital Twin',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.028,
            base_beta=0.0065,
            base_max_gain=58,
            adaptation_rate=0.17,
            metadata={'model_type': 'digital_twin', 'features': ['simulation']}
        ),
        DynamicApproach(
            name='Edge-Collaborative',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.032,
            base_beta=0.006,
            base_max_gain=62,
            adaptation_rate=0.22,
            metadata={'model_type': 'edge_drl', 'features': ['distributed']}
        ),
        DynamicApproach(
            name='FedRSU',
            approach_type=ApproachType.BASELINE,
            base_alpha=0.026,
            base_beta=0.0072,
            base_max_gain=55,
            adaptation_rate=0.19,
            metadata={'model_type': 'federated', 'features': ['privacy']}
        ),
        DynamicApproach(
            name='Hydra-RAN (Proposed)',
            approach_type=ApproachType.PROPOSED,
            base_alpha=0.027,
            base_beta=0.003,
            base_max_gain=82,
            adaptation_rate=0.25,
            metadata={
                'model_type': 'hierarchical_kd',
                'features': ['goal_aware', 'belief_driven', 'adaptive', 'hierarchical']
            }
        ),
        DynamicApproach(
            name='Adaptive Edge AI',
            approach_type=ApproachType.HYBRID,
            base_alpha=0.022,
            base_beta=0.005,
            base_max_gain=65,
            adaptation_rate=0.23,
            metadata={'model_type': 'adaptive', 'features': ['adaptive', 'edge']}
        )
    ]

# ===============================
# Performance Analyzer
# ===============================

class PerformanceAnalyzer:
    """Analyze simulation performance results."""
    
    @staticmethod
    def print_summary(sim: DynamicSimulationFramework, step: Optional[int] = None):
        """Print comprehensive performance summary."""
        if step is None:
            step = sim.current_step - 1 if sim.current_step > 0 else 0
        
        results = sim.results.get(f'step_{step}', {})
        
        print("=" * 90)
        print("DYNAMIC PERFORMANCE EVALUATION SUMMARY")
        print("=" * 90)
        print(f"Simulation Step: {step}")
        print(f"Dataset: {sim.dataset.name if sim.dataset else 'None'}")
        print(f"System Conditions:")
        print(f"  - Latency Range: {sim.params.latency_min}-{sim.params.latency_max} ms")
        print(f"  - Bandwidth: {sim.params.bandwidth} MHz")
        print(f"  - Vehicle Density: {sim.params.vehicle_density} veh/km²")
        print(f"  - Network Congestion: {sim.params.network_congestion:.2f}")
        print("-" * 90)
        
        if sim.history and step < len(sim.history):
            factors = sim.history[step]['factors']
            print("Current Environmental Factors:")
            for factor, value in factors.items():
                print(f"  - {factor}: {value:.3f}")
            print("-" * 90)
        
        # Sort approaches by average KD gain
        sorted_approaches = sorted(sim.approaches, 
                                  key=lambda a: np.mean(results.get(a.name, {}).get('kd_gain', [0])), 
                                  reverse=True)
        
        print("\nAPPROACH PERFORMANCE RANKING:")
        print("-" * 90)
        
        for i, approach in enumerate(sorted_approaches, 1):
            if approach.name in results:
                data = results[approach.name]
                avg_gain = np.mean(data['kd_gain'])
                max_gain = np.max(data['kd_gain'])
                avg_composite = np.mean(data['composite_score'])
                latency_at_max = sim.params.latency[np.argmax(data['kd_gain'])]
                
                print(f"{i}. {approach.name} ({approach.approach_type.value}):")
                print(f"   Avg KD Gain: {avg_gain:.2f}%")
                print(f"   Max KD Gain: {max_gain:.2f}%")
                print(f"   Avg Composite: {avg_composite:.3f}")
                print(f"   Latency at Max Gain: {latency_at_max:.1f} ms")
                
                if approach.parameter_history and len(approach.parameter_history) > step:
                    params = approach.parameter_history[step]
                    base_params = {'alpha': approach.base_alpha, 
                                  'beta': approach.base_beta, 
                                  'max_gain': approach.base_max_gain}
                    
                    print(f"   Parameter Adaptation:")
                    print(f"     α: {base_params['alpha']:.4f} → {params['alpha']:.4f} "
                          f"({((params['alpha']-base_params['alpha'])/base_params['alpha'])*100:+.1f}%)")
                    print(f"     β: {base_params['beta']:.4f} → {params['beta']:.4f} "
                          f"({((params['beta']-base_params['beta'])/base_params['beta'])*100:+.1f}%)")
                    print(f"     Max Gain: {base_params['max_gain']:.1f} → {params['max_gain']:.1f} "
                          f"({((params['max_gain']-base_params['max_gain'])/base_params['max_gain'])*100:+.1f}%)")
                print()
        
        # Calculate improvements over baselines
        if 'Hydra-RAN (Proposed)' in results:
            hydra_avg = np.mean(results['Hydra-RAN (Proposed)']['kd_gain'])
            print("IMPROVEMENT OVER BASELINES:")
            print("-" * 90)
            for approach in sim.approaches:
                if (approach.approach_type == ApproachType.BASELINE and 
                    approach.name in results):
                    baseline_avg = np.mean(results[approach.name]['kd_gain'])
                    improvement = ((hydra_avg - baseline_avg) / baseline_avg) * 100
                    print(f"  vs {approach.name}: {improvement:+.1f}%")
        
        print("=" * 90)
    
    @staticmethod
    def export_results(sim: DynamicSimulationFramework, filename: str):
        """Export simulation results to file."""
        import json
        import pickle
        
        export_data = {
            'parameters': {
                k: v for k, v in sim.params.__dict__.items() 
                if not k.startswith('_') and not callable(v)
            },
            'dataset': {
                k: v for k, v in sim.dataset.__dict__.items() 
                if not k.startswith('_') and not callable(v)
            } if sim.dataset else None,
            'history_summary': [
                {
                    'step': h['step'],
                    'factors': h['factors'],
                    'results': h['results']
                }
                for h in sim.history
            ],
            'approaches': [
                {
                    'name': a.name,
                    'type': a.approach_type.value,
                    'base_parameters': {
                        'alpha': a.base_alpha,
                        'beta': a.base_beta,
                        'max_gain': a.base_max_gain
                    },
                    'final_performance': (
                        sim.results.get(f'step_{sim.current_step-1}', {})
                        .get(a.name, {})
                        if sim.current_step > 0 else {}
                    )
                }
                for a in sim.approaches
            ]
        }
        
        # Save as JSON
        with open(f'{filename}.json', 'w') as f:
            json.dump(export_data, f, indent=2, default=str)
        
        # Save full simulation as pickle
        with open(f'{filename}.pkl', 'wb') as f:
            pickle.dump(sim, f)
        
        print(f"Results exported to {filename}.json and {filename}.pkl")

# ===============================
# Interactive Simulation Controller
# ===============================

class InteractiveSimulationController:
    """Controller for interactive simulation experiments."""
    
    def __init__(self):
        self.sim = DynamicSimulationFramework()
        self.visualizer = SimulationVisualizer()
        self.analyzer = PerformanceAnalyzer()
        
        # Initialize with default approaches
        approaches = create_dynamic_approaches()
        for approach in approaches:
            self.sim.add_approach(approach)
    
    def run_scenario(self, dataset_name: str = 'urban_dynamic',
                    num_steps: int = 10, step_duration: float = 1.0):
        """Run a complete simulation scenario."""
        print(f"\n{'='*90}")
        print(f"RUNNING SCENARIO: {dataset_name.upper()}")
        print(f"{'='*90}")
        
        # Load dataset
        datasets = create_dynamic_dataset_scenarios()
        self.sim.set_dataset(datasets[dataset_name])
        
        # Reset and run simulation
        self.sim.reset()
        self.sim.simulate(num_steps=num_steps, step_duration=step_duration)
        
        # Visualize results
        print(f"\nVisualizing results for step {num_steps-1}...")
        self.visualizer.plot_dynamic_performance(self.sim, step=num_steps-1)
        
        # Print summary
        self.analyzer.print_summary(self.sim, step=num_steps-1)
        
        return self.sim
    
    def run_parameter_sweep(self, param_name: str, 
                           min_val: float, max_val: float, 
                           num_points: int = 10):
        """Run parameter sweep analysis."""
        print(f"\n{'='*90}")
        print(f"PARAMETER SWEEP: {param_name.upper()}")
        print(f"{'='*90}")
        
        values = np.linspace(min_val, max_val, num_points)
        self.visualizer.plot_sensitivity_analysis(self.sim, param_name, values)
        
        return values
    
    def run_comparative_analysis(self, dataset_names: List[str]):
        """Run comparative analysis across multiple datasets."""
        print(f"\n{'='*90}")
        print("COMPARATIVE ANALYSIS ACROSS DATASETS")
        print(f"{'='*90}")
        
        results_summary = {}
        datasets = create_dynamic_dataset_scenarios()
        
        for dataset_name in dataset_names:
            print(f"\nAnalyzing {dataset_name}...")
            self.sim.set_dataset(datasets[dataset_name])
            self.sim.reset()
            self.sim.simulate(num_steps=5)
            
            # Collect average performance
            results_summary[dataset_name] = {}
            for approach in self.sim.approaches:
                if approach.performance_history:
                    avg_gains = [np.mean(step['kd_gain']) 
                               for step in approach.performance_history]
                    results_summary[dataset_name][approach.name] = {
                        'avg_gain': np.mean(avg_gains),
                        'std_gain': np.std(avg_gains),
                        'max_gain': np.max(avg_gains)
                    }
        
        # Plot comparative results
        self._plot_comparative_results(results_summary)
        
        return results_summary
    
    def _plot_comparative_results(self, results_summary: Dict):
        """Plot comparative results."""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        axes = axes.flatten()
        
        # Extract data for plotting
        dataset_names = list(results_summary.keys())
        approach_names = list(results_summary[dataset_names[0]].keys())
        
        # Plot 1: Average performance by dataset
        ax = axes[0]
        x = np.arange(len(dataset_names))
        width = 0.8 / len(approach_names)
        
        for i, approach in enumerate(approach_names):
            offsets = x + (i - len(approach_names)/2 + 0.5) * width
            values = [results_summary[ds][approach]['avg_gain'] for ds in dataset_names]
            ax.bar(offsets, values, width=width, label=approach, alpha=0.7)
        
        ax.set_xlabel('Dataset', fontsize=12)
        ax.set_ylabel('Average KD Gain (%)', fontsize=12)
        ax.set_title('Performance Across Datasets', fontsize=14)
        ax.set_xticks(x)
        ax.set_xticklabels(dataset_names, rotation=45, ha='right')
        ax.legend(fontsize=9, bbox_to_anchor=(1.05, 1))
        ax.grid(True, alpha=0.3, axis='y')
        
        # Plot 2: Performance variation
        ax = axes[1]
        variations = []
        for approach in approach_names:
            stds = [results_summary[ds][approach]['std_gain'] for ds in dataset_names]
            variations.append(np.mean(stds))
        
        bars = ax.bar(range(len(variations)), variations)
        ax.set_xticks(range(len(variations)))
        ax.set_xticklabels(approach_names, rotation=45, ha='right', fontsize=9)
        ax.set_ylabel('Performance Variation (Std Dev)', fontsize=12)
        ax.set_title('Approach Stability', fontsize=14)
        
        # Color bars by approach type
        for i, (bar, approach) in enumerate(zip(bars, approach_names)):
            if 'Hydra-RAN' in approach:
                bar.set_color('black')
            elif 'Proposed' in approach:
                bar.set_color('red')
        
        # Plot 3: Relative performance heatmap
        ax = axes[2]
        performance_matrix = np.zeros((len(dataset_names), len(approach_names)))
        for i, ds in enumerate(dataset_names):
            for j, approach in enumerate(approach_names):
                performance_matrix[i, j] = results_summary[ds][approach]['avg_gain']
        
        im = ax.imshow(performance_matrix, cmap='YlOrRd', aspect='auto')
        ax.set_xticks(range(len(approach_names)))
        ax.set_xticklabels(approach_names, rotation=45, ha='right', fontsize=8)
        ax.set_yticks(range(len(dataset_names)))
        ax.set_yticklabels(dataset_names, fontsize=9)
        ax.set_title('Performance Heatmap', fontsize=14)
        plt.colorbar(im, ax=ax, label='KD Gain (%)')
        
        # Plot 4: Improvement over best baseline
        ax = axes[3]
        improvements = []
        for ds in dataset_names:
            baseline_max = max([results_summary[ds][a]['avg_gain'] 
                              for a in approach_names 
                              if 'Hydra-RAN' not in a and 'Proposed' not in a])
            hydra_perf = results_summary[ds]['Hydra-RAN (Proposed)']['avg_gain']
            improvements.append(((hydra_perf - baseline_max) / baseline_max) * 100)
        
        bars = ax.bar(range(len(improvements)), improvements, color=['green' if x > 0 else 'red' for x in improvements])
        ax.set_xticks(range(len(improvements)))
        ax.set_xticklabels(dataset_names, rotation=45, ha='right')
        ax.set_ylabel('Improvement Over Best Baseline (%)', fontsize=12)
        ax.set_title('Hydra-RAN Performance Improvement', fontsize=14)
        ax.grid(True, alpha=0.3, axis='y')
        
        # Add value labels
        for bar, val in zip(bars, improvements):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:+.1f}%', ha='center', va='bottom' if val > 0 else 'top')
        
        plt.suptitle('Comparative Performance Analysis', fontsize=16)
        plt.tight_layout()
        plt.show()

# ===============================
# Main Execution
# ===============================

def main():
    """Main execution function."""
    print("Initializing Dynamic Simulation Framework...")
    print("=" * 90)
    
    # Create interactive controller
    controller = InteractiveSimulationController()
    
    # Run main scenario
    print("\n1. Running Urban Dynamic Scenario...")
    sim = controller.run_scenario('urban_dynamic', num_steps=8)
    
    # Run parameter sensitivity analysis
    print("\n\n2. Running Parameter Sensitivity Analysis...")
    controller.run_parameter_sweep('bandwidth', 20, 200, 8)
    controller.run_parameter_sweep('vehicle_density', 10, 150, 8)
    
    # Run comparative analysis
    print("\n\n3. Running Comparative Analysis...")
    controller.run_comparative_analysis(['urban_dynamic', 'highway_stable', 'dense_urban'])
    
    # Demonstrate dynamic modifications
    print("\n\n4. Demonstrating Dynamic Modifications...")
    print("-" * 90)
    
    # Modify parameters and show effect
    print("\na) Increasing network congestion from 0.3 to 0.8...")
    controller.sim.update_parameters(network_congestion=0.8)
    controller.sim.reset()
    controller.sim.simulate(num_steps=3)
    controller.analyzer.print_summary(controller.sim)
    
    print("\nb) Modifying dataset complexity from 0.7 to 0.9...")
    controller.sim.modify_dataset(complexity=0.9)
    controller.sim.reset()
    controller.sim.simulate(num_steps=3)
    controller.analyzer.print_summary(controller.sim)
    
    print("\nc) Changing latency range from 10-120ms to 20-200ms...")
    controller.sim.update_parameters(latency_min=20, latency_max=200)
    controller.sim.reset()
    controller.sim.simulate(num_steps=3)
    controller.visualizer.plot_dynamic_performance(controller.sim)
    
    # Export results
    print("\n\n5. Exporting Results...")
    controller.analyzer.export_results(controller.sim, 'simulation_results')
    
    print("\n" + "=" * 90)
    print("SIMULATION COMPLETE")
    print("=" * 90)
    
    return controller.sim

def quick_demo():
    """Quick demonstration of dynamic behavior."""
    print("QUICK DEMONSTRATION OF DYNAMIC SIMULATION")
    print("=" * 90)
    
    # Create simulation
    sim = DynamicSimulationFramework()
    datasets = create_dynamic_dataset_scenarios()
    
    # Add approaches
    approaches = create_dynamic_approaches()
    for approach in approaches:
        sim.add_approach(approach)
    
    # Test 1: Baseline performance
    print("\nTest 1: Baseline performance with urban dataset")
    sim.set_dataset(datasets['urban_dynamic'])
    sim.simulate(num_steps=5)
    PerformanceAnalyzer.print_summary(sim)
    
    # Test 2: Change to noisy dataset
    print("\n\nTest 2: Switching to noisy dense urban dataset")
    sim.set_dataset(datasets['dense_urban'])
    sim.reset()
    sim.simulate(num_steps=5)
    PerformanceAnalyzer.print_summary(sim)
    
    # Test 3: Modify system parameters
    print("\n\nTest 3: Increasing bandwidth and reducing congestion")
    sim.update_parameters(bandwidth=150, network_congestion=0.1)
    sim.reset()
    sim.simulate(num_steps=5)
    PerformanceAnalyzer.print_summary(sim)
    
    return sim

# ===============================
# Execution Entry Points
# ===============================

if __name__ == "__main__":
    # Run full simulation
    simulation = main()
    
    # Uncomment for quick demo
    # simulation = quick_demo()
    
    # Uncomment for specific experiments
    # controller = InteractiveSimulationController()
    # controller.run_scenario('highway_stable', num_steps=10)
